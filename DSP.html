<html>
	<head>
		<title>DSP</title>
		<style type="text/css">
			body{font-family: Trebuchet MS;}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 20px;padding: 1%;font-family:sans-serif;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 10px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 18px;font-weight: bold;}
			.text{width: 95%;font-size: 16px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 16px;}
			.image{width: 95%;font-size: 16px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title">Gender Classification From Speech</div>

			<div class="authors">

				<!-- Start edit here  -->
				<p>P.Revanth, Roll No: 150102047 Branch: ECE</p>; &nbsp; &nbsp;
				<p>P.Sai Krupal Reddy, Roll No: 150102049, Branch: ECE</p>; &nbsp; &nbsp;
				<p>N.Sanjay, Roll No: 150102038, Branch: ECE</p>; &nbsp; &nbsp;
				<p>M.Harshith, Roll No: 150102034, Branch: ECE</p>; &nbsp; &nbsp;
				<p>M.V.S.Surya Teja, Roll No: 150102033, Branch: ECE</p>; &nbsp; &nbsp;
				<!-- Stop edit here -->

			</div>


			<div class="section">
				<div class="heading">Abstract</div>
				<div class="text">

					<!-- Start edit here  -->
					The primary aim of our project is to build Gender classification system based on the speech.The system includes feature extractor which extracts 
MFCC(Mel Frequency Cepstral Coefficients) and we also extract delta coefficients,delta-delta coefficients from MFCC and generate a feature vector.Then we do spherical
k-means clustering and then we implement bag of words and then predict the gender.
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->
					Speech is the most natural and efficient way of communication between humans.This project aims at classifying the gender from speech.The first step is to extract 
feature from the audio data.One of the best features that are available with respect to the frequency of identifying gender is
 MFCC (Mel Frequency Cepstral Coefficients).It is a non-parametric frequency domain approach, which is based on a human 
auditory perception system.
					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
						Human listeners are capable of extracting information from the accoustic signal beyond just the linguistic message like speakers personality, emotional state, gender
e.t.c..Our project aims at enabling the computer to classify the gender.
						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading">1.2 Figure</div>
					<div class="image">

						<!-- Start edit here  -->
						
						<img src="DSP.jpg" alt="This text displays when the image is umavailable" width="300px" height=""/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.3 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						Gender Recognition of a speaker has various
potential applications. In Sparse Estimation Technique,the extracted fundamental frequency is used for finding auto correlation function of speech signal for identifying
the gender. The reported gender recognition accuracy is 90
to 95%. But the fundamental frequency estimation
may be difficult in case of noisy environment. In this
situation more complex methods can be proposed to
improve fundamental frequency estimation. In Mel Frequency CepstralCoefficients (MFCC), features are extracted for voiced
vowels where the distinction of male/female is most
significant & accuracy is better. This technique does not
propose the method for extraction of segments
corresponding to selected vowels from the continuous
speech audio stream. In Two Stage Classification Method, frequency is estimated for gender recognition. The
accuracy is increased. The achieved accuracy is low. If the
estimated frequency is far from the zone then male and
female frequencies are overlapped. Therefore it is difficult
to identification. In Lab VIEW technique, identification
of the gender and removing gender specific components,
higher compression rate can be achieved. Here the
information is enhanced to save the Bandwidth. This
method does not extract the vowels from speech. The value
is obtained for formant1 were not completely correct as
they were obtained by processing all the samples of speech.
Hence it is difficult to identify the gender. Linear Predictive
Coding (LPC) method used for Feature extraction. A
well chosen feature can result in quality recognition. PDA
based on average magnitude difference function has
relatively low computational cost and it is easy to
implement. In which wrongly chosen feature can result in
poor recognition. By the use of Machine Language
algorithm (MLP), 92.5% accuracy will be achieved. But
it is difficult to detection of females as compared to males.
Seven different methods are combined for Automatic
gender and speaker recognition. Three baseline subsystems
Gaussian Mixture Model (GMM), Mel Frequency Cepstral
Coefficients (MFCC), Support Vector Machine (SVM) and
four subsystems SVM based on UBM weight posterior
probability super vector, sparse representation based on
UBM weight posterior probability super vector, SVM
based on GMM Maximum Likely hood Linear
Regression(MLLR), SVM based on the polynomial
expansion of the coefficients. It is suitable for large scale
online adaptive learning due to its property of no new
training effort required. But the performance is low. To
increase the performance, weighted summation based
fusion of these seven subsystems at the score level is
demonstrated. The result obtained is 3.1% and 3.8% which
is the absolute improvement. Gaussian Mixture model
helps to extract higher level information from the speech
signal. This method is a simple and effective. The
disadvantage of this technique is the higher levels of
information will not provide good performance and may
need to be fused with more traditional acoustic-based
systems.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.4 Proposed Approach</div>
					<div class="text">

						<!-- Start edit here  -->
						Describe your approach briefly here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.5 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">2. Proposed Approach</div>
				<div class="text">

					<!-- Start edit here  -->
					The Proposed approach for this Project is first to extract the MFCCs(mel frequency cepstral coefficients) and next we have to compute the Delta coefficients,Delta-Delta coefficients from the MFCCs.Now we make a feature vector comprising of all the above coefficients and now we fed it to the Sperical K-means clusturing algorithem.We also computed bagofwords which is computed by using training datasets of male and female by clusturing them. 
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">3. Experiments &amp; Results</div>
				<div class="subsection">
					<div class="heading">3.1 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						We have taken a <a href = "https://drive.google.com/open?id=1EPXUoW1saEDBKE0AnEKNCePZlUEHTezf" title = "Click here for Datasets!">DATASET</a> which contains a test dataset and a training dataset with both male and female speech samples.The test and training datasets contains 590
voice samples each of each gender.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">3.2 Discussion</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">4. Conclusions</div>
				<div class="subsection">
					<div class="heading">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						Firstly, we want to decrease the error probability.Then we want to increase the predicatability even in the presence of noise.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
